{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\chatbot\\\\medicalchatbot'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\chatbot\\\\medicalchatbot'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 2345\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaswi\\AppData\\Local\\Temp\\ipykernel_14120\\4043855499.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "d:\\chatbot\\medicalchatbot\\medibot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
    "GEMINI_API_KEY=os.environ.get('GEMINI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "index_name = \"medicalbot\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1a38e107a70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1ac7fd50-bdd3-4d99-ba63-0671a38811c9', metadata={'author': 'Tierney, Lawrence M.; Saint, Sanjay.; Whooley, Mary A.', 'creationdate': '2010-12-22T13:15:56+00:00', 'creator': 'PyPDF', 'keywords': '0071637907\\r\\n9780071637909', 'moddate': '2018-08-02T09:28:12+05:30', 'page': 412.0, 'page_label': '400', 'producer': 'PyPDF', 'source': 'Data\\\\Current Essentials of Medicine.pdf', 'subject': 'McGraw-Hill Medical', 'title': 'Current Essentials of Medicine', 'total_pages': 607.0}, page_content='400 Current Essentials of Medicine\\nAcne Vulgaris\\n■ Essentials of Diagnosis\\n• Often occurs at puberty, though onset may be delayed until the\\nthird or fourth decade\\n• Open and closed comedones the hallmarks\\n• Severity varies from comedone to papular or pustular inﬂamma-\\ntory acne to cysts or nodules\\n• Face, neck, upper chest, and back may be affected\\n• Pigmentary changes and severe scarring can occur\\n■ Differential Diagnosis\\n• Acne rosacea, perioral dermatitis, gram-negative folliculitis, tinea'),\n",
       " Document(id='1fff88ea-9a57-4b6b-9127-f2d877b27d9d', metadata={'author': 'Tierney, Lawrence M.; Saint, Sanjay.; Whooley, Mary A.', 'creationdate': '2010-12-22T13:15:56+00:00', 'creator': 'PyPDF', 'keywords': '0071637907\\r\\n9780071637909', 'moddate': '2018-08-02T09:28:12+05:30', 'page': 435.0, 'page_label': '423', 'producer': 'PyPDF', 'source': 'Data\\\\Current Essentials of Medicine.pdf', 'subject': 'McGraw-Hill Medical', 'title': 'Current Essentials of Medicine', 'total_pages': 607.0}, page_content='Acad Dermatol 2007;57:737. [PMID: 17939933]\\n15'),\n",
       " Document(id='9c03ba49-30bb-4a47-af8f-e8decc1e7a8d', metadata={'author': 'Tierney, Lawrence M.; Saint, Sanjay.; Whooley, Mary A.', 'creationdate': '2010-12-22T13:15:56+00:00', 'creator': 'PyPDF', 'keywords': '0071637907\\r\\n9780071637909', 'moddate': '2018-08-02T09:28:12+05:30', 'page': 412.0, 'page_label': '400', 'producer': 'PyPDF', 'source': 'Data\\\\Current Essentials of Medicine.pdf', 'subject': 'McGraw-Hill Medical', 'title': 'Current Essentials of Medicine', 'total_pages': 607.0}, page_content='inﬂammatory papules and cysts\\n• Oral isotretinoin useful in some who fail antibiotic therapy; preg-\\nnancy prevention and monitoring essential\\n• Surgical and laser techniques available to treat scarring\\n■ Pearl\\nDon’t waste time continuing failing therapies in scarring acne—treat\\naggressively to prevent further scars.\\nReference\\nHaider A, Shaw JC. Treatment of acne vulgaris. JAMA 2004;292:726. [PMID:\\n15304471]\\n15')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\chatbot\\medicalchatbot\\medibot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "❌ Missing API keys! Check your .env file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Check API keys\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m GOOGLE_API_KEY \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m PINECONE_API_KEY:\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Missing API keys! Check your .env file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Initialize Flask app\u001b[39;00m\n\u001b[0;32m     23\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: ❌ Missing API keys! Check your .env file."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone\n",
    "from langchain_community.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = \"medicalbot\"\n",
    "\n",
    "# Check API keys\n",
    "if not GOOGLE_API_KEY or not PINECONE_API_KEY:\n",
    "    raise ValueError(\"❌ Missing API keys! Check your .env file.\")\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Configure Gemini AI\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Check if index exists in Pinecone\n",
    "existing_indexes = [index_info['name'] for index_info in pc.list_indexes()]\n",
    "if INDEX_NAME not in existing_indexes:\n",
    "    raise ValueError(f\"❌ Index '{INDEX_NAME}' not found in Pinecone. Check your Pinecone console.\")\n",
    "\n",
    "# Load Retriever\n",
    "retriever = PineconeVectorStore.from_existing_index(\n",
    "    INDEX_NAME,\n",
    "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    ")\n",
    "print(\"✅ Retriever loaded successfully!\")\n",
    "\n",
    "# In-memory chat history (Replace with Redis, MongoDB, or database for persistence)\n",
    "chat_histories = {}\n",
    "\n",
    "def get_chat_history(session_id):\n",
    "    \"\"\"Retrieve chat history for a session, or create a new one.\"\"\"\n",
    "    if session_id not in chat_histories:\n",
    "        chat_histories[session_id] = ChatMessageHistory()\n",
    "    return chat_histories[session_id]\n",
    "\n",
    "def generate_response_with_retry(prompt, max_retries=3, delay=5):\n",
    "    \"\"\"Handles Gemini AI API rate limits with retry logic.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except genai.RateLimitError:\n",
    "            print(f\"⚠️ Rate limit reached. Retrying in {delay} seconds... (Attempt {attempt + 1})\")\n",
    "            time.sleep(delay)\n",
    "    return \"❌ Error: Rate limit exceeded. Please try again later.\"\n",
    "\n",
    "def custom_rag_chain(query, session_id):\n",
    "    \"\"\"Retrieves relevant documents and generates an answer with history.\"\"\"\n",
    "    history = get_chat_history(session_id)\n",
    "    \n",
    "    retrieved_docs = retriever.as_retriever().invoke(query)  \n",
    "    past_messages = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in history.messages])\n",
    "\n",
    "    if retrieved_docs:\n",
    "        retrieved_text = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "        prompt = f\"Chat History:\\n{past_messages}\\n\\nBased on the following medical references, answer the question:\\n\\n{retrieved_text}\\n\\nQuestion: {query}\"\n",
    "    else:\n",
    "        print(\"⚠️ No relevant documents found. Answering from general knowledge...\")\n",
    "        prompt = f\"Chat History:\\n{past_messages}\\n\\nQuestion: {query}\"\n",
    "\n",
    "    response = generate_response_with_retry(prompt)\n",
    "\n",
    "    # Store messages in history\n",
    "    history.add_user_message(query)\n",
    "    history.add_ai_message(response)\n",
    "\n",
    "    return response\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    \"\"\"Return a simple JSON response for the root route.\"\"\"\n",
    "    return jsonify({\"message\": \"Welcome to the Medical Chatbot!\"})\n",
    "\n",
    "@app.route(\"/chat\", methods=[\"POST\"])\n",
    "def chat():\n",
    "    data = request.json\n",
    "    query = data.get(\"message\", \"\")\n",
    "    session_id = data.get(\"session_id\", \"default\")  # Unique identifier for each conversation\n",
    "\n",
    "    if not query:\n",
    "        return jsonify({\"error\": \"No message provided\"}), 400\n",
    "\n",
    "    response = custom_rag_chain(query, session_id)\n",
    "    return jsonify({\"response\": response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    port = int(os.getenv(\"PORT\", 5000))  # Render assigns a port dynamically\n",
    "    app.run(host=\"0.0.0.0\", port=port, debug=True, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
